<div align="center">
  <h1>ğŸ¤ Projeto de TranscriÃ§Ã£o e DiarizaÃ§Ã£o de Ãudio</h1>
  <img src="https://media2.giphy.com/media/v1.Y2lkPTc5MGI3NjExYXFyenR0Y3cxbXR1M2c3OGN2bDUyaDdiYmVpMjliZDZyYmM2MmczYiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/bJ4TVNYNUympPgcpem/giphy.gif" alt="TranscriÃ§Ã£o em aÃ§Ã£o">
</div>

<div align="center">
  <style>
    img {
      margin: 60 60px; /* Adiciona um espaÃ§o de 10px entre cada imagem */
    }
  </style>
  <img src="https://img.shields.io/badge/status-em%20desenvolvimento-orange" alt="Build Status"> 
  <img src="https://img.shields.io/badge/python-3.12-blue" alt="Python version">
  <img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT">
  <img src="https://img.shields.io/badge/Dependencies-Required-brightgreen" alt="Dependencies">
  <img src="https://img.shields.io/badge/Hugging%20Face-Access-orange" alt="Hugging Face">
</div>


## ğŸ“Œ DescriÃ§Ã£o
Este projeto tem como objetivo realizar a extraÃ§Ã£o de Ã¡udio de um vÃ­deo, transcrevÃª-lo utilizando o modelo WhisperX e identificar diferentes falantes (diarizaÃ§Ã£o). O resultado final Ã© um arquivo de texto contendo a transcriÃ§Ã£o organizada e identificada por falante.

## ğŸš€ Funcionalidades
âœ… ExtraÃ§Ã£o de Ã¡udio de arquivos MP4.  
âœ… TranscriÃ§Ã£o automÃ¡tica do Ã¡udio extraÃ­do.  
âœ… DiarizaÃ§Ã£o para identificar diferentes falantes.  
âœ… GeraÃ§Ã£o de um arquivo de transcriÃ§Ã£o formatado.


## ğŸ“‚ Estrutura do Projeto
```
/
â”‚   .env
â”‚   .gitignore
â”‚   ffmpeg.exe
â”‚   ffplay.exe
â”‚   ffprobe.exe
â”‚   LICENSE
â”‚   main.py
â”‚   README.md
â”‚   requirements.txt
â”‚
â”œâ”€â”€â”€.vscode
â”‚       launch.json
â”‚
â”œâ”€â”€â”€cache
â”‚       removePycache.ps1
â”‚
â”œâ”€â”€â”€model
â”‚   â”œâ”€â”€â”€.locks
â”‚   â”‚   â””â”€â”€â”€models--Systran--faster-whisper-small
â”‚   â””â”€â”€â”€models--Systran--faster-whisper-small
â”‚       â”œâ”€â”€â”€blobs
â”‚       â”œâ”€â”€â”€refs
â”‚       â”‚       main
â”‚       â”‚
â”‚       â””â”€â”€â”€snapshots
â”‚           â””â”€â”€â”€536b0662742c02347bc0e980a01041f333bce120
â”‚                   config.json
â”‚                   model.bin
â”‚                   tokenizer.json
â”‚                   vocabulary.txt
â”‚
â”œâ”€â”€â”€resources
â”‚       ğŸ“¹ [Flow](resources/flow.mp4)
â”‚       ğŸ“„ [TranscriÃ§Ã£o gerada](resources/transcription_flow.txt)
â”‚
â”œâ”€â”€â”€temp
â””â”€â”€â”€utils
        audio.py
        device.py
        imports.py
        memory.py
        transcription.py
```

## ğŸ”§ Requisitos
ğŸ›  Python 3.12 ou superior.
ğŸ›  DependÃªncias: Instale as bibliotecas necessÃ¡rias listadas no arquivo `requirements.txt`.
ğŸ›  WhisperX: Biblioteca para transcriÃ§Ã£o de Ã¡udio.
ğŸ›  MoviePy e Pydub: Para manipulaÃ§Ã£o de Ã¡udio e vÃ­deo.
ğŸ›  Chave da Hugging Face: NecessÃ¡ria para acessar modelos prÃ©-treinados.

## ğŸ“¥ InstalaÃ§Ã£o
1ï¸âƒ£ Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/marcosbelo-fiepb/automated-speech-recognition.git
   cd automated-speech-recognition
   ```
2ï¸âƒ£ Instale as dependÃªncias com pip:
   ```bash
   pip install -r requirements.txt
   ```
3ï¸âƒ£ Configure a chave de autenticaÃ§Ã£o da Hugging Face:

- Crie um arquivo `.env` na raiz do projeto e adicione:
   ```bash
   HUGGING=<sua-chave-hugging-face>
   ```
- Ou exporte a variÃ¡vel de ambiente no terminal:
   ```bash
   export HUGGING=<sua-chave-hugging-face>
   ```

## â–¶ï¸ ExecuÃ§Ã£o
Para iniciar o processo de transcriÃ§Ã£o e diarizaÃ§Ã£o, execute o script principal:
```bash
python -m main
```

## ğŸ“œ Exemplo de SaÃ­da
```
ğŸ”‰ Falante: Speaker_1
ğŸ“„ Frase: Bom dia a todos.
â³ InÃ­cio: 0.05 min
â³ Fim: 0.10 min
----------------------------------------
ğŸ”‰ Falante: Speaker_2
ğŸ“„ Frase: Vamos comeÃ§ar a reuniÃ£o.
â³ InÃ­cio: 0.12 min
â³ Fim: 0.18 min
----------------------------------------
```

ğŸ“‚ [Clique aqui para visualizar um exemplo de transcriÃ§Ã£o completa](resources/transcription_flow.txt)<br>
ğŸ“‚ [Clique aqui para visualizar o vÃ­deo original](resources/flow.mp4)

## â— PossÃ­veis Erros e SoluÃ§Ãµes
âŒ **Erro ao carregar o modelo**: Verifique se a chave da Hugging Face estÃ¡ configurada corretamente.
âŒ **Erro ao extrair o Ã¡udio**: Confirme que o arquivo MP4 estÃ¡ na pasta `resources/`.
âŒ **Alto consumo de memÃ³ria**: Certifique-se de rodar a limpeza de memÃ³ria apÃ³s a execuÃ§Ã£o.

## ğŸ¤ ContribuiÃ§Ã£o
ContribuiÃ§Ãµes sÃ£o bem-vindas! Siga os passos abaixo:

1ï¸âƒ£ FaÃ§a um fork do repositÃ³rio.

2ï¸âƒ£ Crie uma branch para sua feature:
   ```bash
   git checkout -b feature/nova-feature
   ```

3ï¸âƒ£ Commit suas alteraÃ§Ãµes:
   ```bash
   git commit -m 'Adiciona nova feature'
   ```

4ï¸âƒ£ Envie para a branch:
   ```bash
   git push origin feature/nova-feature
   ```

5ï¸âƒ£ Abra um Pull Request.

Para relatar problemas, acesse a seÃ§Ã£o [Issues](https://github.com/marcosbelo-fiepb/automated-speech-recognition/issues).

## ğŸ“œ LicenÃ§a
Este projeto estÃ¡ licenciado sob a MIT License. Consulte o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ“¬ Contato
ğŸ‘¤ **Autor**: Marcos Belo
ğŸ“§ **E-mail**: [marcosbelods@gmail.com](mailto:marcosbelods@gmail.com)